% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/explainability.R
\name{fw.xpy}
\alias{fw.xpy}
\title{Forward variable selection for PDP explanation}
\usage{
fw.xpy(model, x, target, ...)
}
\arguments{
\item{model}{A model with corresponding predict function that returns numeric values.}

\item{x}{Data frame.}

\item{target}{Character specifying the name of the (numeric) target variable (must be contained in data).}

\item{...}{Further arguments to be passed to the \code{predict()} method of the \code{model}.}
}
\value{
Object of class \code{vsexp} containing the following elements:

\item{selection.order}{Vector of variable names in order of their entrance to the PD function during the variable selection process.}

\item{explainability}{Explainabilities after the different iterations of the variable selection.}

\item{details}{A data frame containing the explainabilities for all variables (rows) if they were entered in the model at each step (columns).}
}
\description{
Computes forward variable selection for partial dependence function based on explainability.
}
\examples{
\dontrun{
library(pdp)
library(randomForest)
data(boston)
set.seed(42)
boston.rf <- randomForest(cmedv ~ ., data = boston)
vs <- fw.xpy(boston.rf, boston, "cmedv")
vs

plot(vs)
}

}
\references{
\itemize{
    \item Szepannek, G. (2019): How Much Can We See? A Note on Quantifying Explainability of Machine Learning Models,
          \href{https://arxiv.org/abs/1910.13376}{\emph{arXiv:1910.13376 [stat.ML]}}.
  }
}
\author{
\email{gero.szepannek@web.de}
}
